{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: right\">\n",
    "  <img src=\"../images/dtlogo.png\" alt=\"Logo\" width=\"200\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš™ðŸ’» 01 - OAKD basic integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial you will learn how to create a simple pipeline to read the images from the **OAK-D**.<br>\n",
    "You can plug your **OAK-D** to your laptop and start running the cells below.<br>\n",
    "The code you write here can also be tested on a **Duckiebot** (tested on **DB21M**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Importing Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import numpy as np\n",
    "import cv2\n",
    "from typing import List, Dict, Callable, Optional, Any\n",
    "\n",
    "import depthai as dai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a pipeline\n",
    "\n",
    "The \"pipeline\" is an object documented in the [`depthai` API](https://docs.luxonis.com/projects/api/en/latest/) and can be initialized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def create_pipeline() -> dai.Pipeline:\n",
    "    pipeline = dai.Pipeline()\n",
    "    pipeline.setOpenVINOVersion(version=dai.OpenVINO.Version.VERSION_2021_3)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and configuring nodes\n",
    "\n",
    "\"Nodes\" (not ROS nodes) are different types of sensing modalities of the OAK-D. For example: images, stereo, or neural networks. They are configured using a \"pipeline\" object as a reference, which tracks all of the nodes that get created and pass them onto the OAK-D hardware to configure the device internally once the structure is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def create_nodes(pipeline: dai.Pipeline) -> Dict[str, dai.Node]:\n",
    "    # LEFT CAMERA\n",
    "    cam_left = pipeline.createMonoCamera()\n",
    "    cam_left.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "    cam_left.setResolution(\n",
    "        dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "\n",
    "    # RIGHT CAMERA\n",
    "    cam_right = pipeline.createMonoCamera()\n",
    "    cam_right.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "    cam_right.setResolution(\n",
    "        dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "\n",
    "    # RGB CAMERA\n",
    "    cam_rgb = pipeline.createColorCamera()\n",
    "    cam_rgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n",
    "    cam_rgb.setResolution(\n",
    "        dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "    cam_rgb.setColorOrder(\n",
    "        dai.ColorCameraProperties.ColorOrder.RGB)\n",
    "    cam_rgb.setInterleaved(False)\n",
    "    cam_rgb.setPreviewSize(640, 400)\n",
    "\n",
    "    # STEREO\n",
    "    stereo = pipeline.createStereoDepth()\n",
    "    stereo.initialConfig.setConfidenceThreshold(150)\n",
    "    stereo.initialConfig.setMedianFilter(\n",
    "        dai.StereoDepthProperties.MedianFilter.KERNEL_7x7)\n",
    "    stereo.setLeftRightCheck(False)\n",
    "    stereo.setExtendedDisparity(False)  # True = better for short-range\n",
    "    stereo.setSubpixel(False)  # True = better for long-range\n",
    "    stereo.setRectifyMirrorFrame(False)\n",
    "\n",
    "    return {\n",
    "        'left': cam_left,\n",
    "        'right': cam_right,\n",
    "        'rgb': cam_rgb,\n",
    "        'stereo': stereo\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "\n",
    "Output links are [a special type of node](https://docs.luxonis.com/projects/api/en/latest/components/nodes/xlink_out/) which exist at the interface of the OAK-D hardware and the interface of your computer or Duckiebot. They provide a way to access the data perceived by the OAK-D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def create_output_links(pipeline: dai.Pipeline) -> Dict[str, dai.XLinkOut]:\n",
    "    xout_links = {\n",
    "        'left': pipeline.createXLinkOut(),\n",
    "        'right': pipeline.createXLinkOut(),\n",
    "        'rgb': pipeline.createXLinkOut(),\n",
    "        'disparity': pipeline.createXLinkOut()\n",
    "    }\n",
    "    for name, xout_link in xout_links.items():\n",
    "        xout_link.setStreamName(name)\n",
    "        xout_link.input.setBlocking(False)\n",
    "    return xout_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking nodes to each other\n",
    "\n",
    "The various inputs and outputs of nodes need to be linked together to define the data flow, i.e. _what_ goes _where_? This will be tracked internally by the \"pipeline\" object and later used to configure the OAK-D device. For example, for a stereo node we need to define the two input images. For the output nodes, they need to know which \"upstream\" node in the computational graph they should be receiving data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def link_nodes_and_outputs(nodes: Dict[str, dai.Node],\n",
    "                           outputs: Dict[str, dai.XLinkOut]) -> None:\n",
    "    # Raw RGB image --> Output to host\n",
    "    nodes['rgb'].preview.link(outputs['rgb'].input)\n",
    "    # Disparity --> link the raw left & right images as input to stereo\n",
    "    nodes['left'].out.link(nodes['stereo'].left)\n",
    "    nodes['right'].out.link(nodes['stereo'].right)\n",
    "    nodes['stereo'].disparity.link(outputs['disparity'].input)\n",
    "    # Rectified images --> Output to host\n",
    "    nodes['stereo'].rectifiedLeft.link(outputs['left'].input)\n",
    "    nodes['stereo'].rectifiedRight.link(outputs['right'].input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a device\n",
    "\n",
    "Once all of the nodes are initialized, configured, and properly linked together, the device can be created. The computer or Duckiebot will try to search for an OAK-D device using the `depthai` library and to configure the hardware using our \"pipeline\" object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def create_device(pipeline: dai.Pipeline) -> dai.Device:\n",
    "    device = dai.Device(pipeline, usb2Mode=False)\n",
    "    device.setLogLevel(dai.LogLevel.DEBUG)\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output queues\n",
    "\n",
    "Remember those special \"output links\"? In order to read them, we need to initialize some \"output queues\" which will link to those outputs on the computer or Duckiebot side of things.\n",
    "\n",
    "If a queue is \"blocking\", when a queue is full, any new incoming data will be dropped from the queue until the first item is read (popped) from the queue and a new space gets freed up. In contrast, a non-blocking queue will always insert new incoming data into the queue, and if the queue is filled up, the oldest data will get dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def create_output_queues(device: dai.Device,\n",
    "                         outputs: Dict[str, dai.XLinkOut]) -> Dict[str, dai.DataOutputQueue]:\n",
    "    queues = dict()\n",
    "    for name, xout_link in outputs.items():\n",
    "        queues[name] = device.getOutputQueue(name=name, maxSize=1, blocking=False)\n",
    "    return queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "With everything set up, let's create a utility function to read some specific requested data from the OAK-D, and return it in a dictionary mapping from the data name to the raw data (e.g. a Numpy array containing image data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def read_data(requested_data: List[str],\n",
    "              output_queues: Dict[str, dai.DataOutputQueue]) -> Dict[str, Any]:\n",
    "    data = {name: None for name in requested_data}\n",
    "    for name in requested_data:\n",
    "        if name not in output_queues.keys():\n",
    "            continue\n",
    "        if name in ('left', 'right', 'rgb'):\n",
    "            data[name] = output_queues[name].get().getCvFrame()\n",
    "        elif name == 'disparity':\n",
    "            data[name] = output_queues[name].get().getFrame()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and visualize\n",
    "\n",
    "Here is a simple helper function which uses the functions we've written to set up the OAK-D, continuously read data, and visualize it. This function optionally includes an \"image processing\" function which post-processes the data that we will read. This will come in handy for visualizing disparity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "ImageProcFunc = Callable[[np.ndarray], np.ndarray]\n",
    "\n",
    "def hello_oakd(output_name: str,\n",
    "               im_proc: Optional[ImageProcFunc]=None) -> None:\n",
    "    display_handle = display(None, display_id=True)\n",
    "    pipeline = create_pipeline()\n",
    "    nodes = create_nodes(pipeline)\n",
    "    outputs = create_output_links(pipeline)\n",
    "    link_nodes_and_outputs(nodes, outputs)\n",
    "    device = create_device(pipeline)\n",
    "    output_queues = create_output_queues(device, outputs)\n",
    "    try:\n",
    "        while True:\n",
    "            data = read_data([output_name], output_queues)\n",
    "            if output_name in data.keys():\n",
    "                frame = data[output_name]\n",
    "                if im_proc is not None:\n",
    "                    frame = im_proc(frame)\n",
    "                _, frame = cv2.imencode('.jpeg', frame)\n",
    "                display_handle.update(Image(data=frame.tobytes()))\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        pass\n",
    "        # display_handle.update(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "import cv2\n",
    "import depthai as dai\n",
    "import numpy as np\n",
    "\n",
    "# Start defining a pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Define a source - color camera\n",
    "cam_rgb = pipeline.createColorCamera()\n",
    "cam_rgb.setPreviewSize(300, 300)\n",
    "cam_rgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n",
    "cam_rgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "cam_rgb.setInterleaved(False)\n",
    "cam_rgb.setColorOrder(dai.ColorCameraProperties.ColorOrder.RGB)\n",
    "\n",
    "# Create output\n",
    "xout_rgb = pipeline.createXLinkOut()\n",
    "xout_rgb.setStreamName(\"rgb\")\n",
    "cam_rgb.preview.link(xout_rgb.input)\n",
    "\n",
    "display_handle = display(None, display_id=True)\n",
    "print(\"ciao\")\n",
    "# Pipeline defined, now the device is connected to\n",
    "with dai.Device(pipeline) as device:\n",
    "    # Start pipeline\n",
    "    device.startPipeline()\n",
    "    print(\"ciao1\")\n",
    "    # Output queue will be used to get the rgb frames from the output defined above\n",
    "    q_rgb = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "\n",
    "    while True:\n",
    "        print(\"ciao2\")\n",
    "        in_rgb = q_rgb.get()  # blocking call, will wait until a new data has arrived\n",
    "\n",
    "        # Retrieve 'bgr' (opencv format) frame\n",
    "        _, frame = cv2.imencode('.jpeg',  in_rgb.getCvFrame())\n",
    "        display_handle.update(Image(data=frame.tostring()))\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_oakd('rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_oakd('left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_oakd('right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparity_to_rgb(disparity: np.ndarray) -> np.ndarray:\n",
    "    norm = cv2.normalize(disparity, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    colored = cv2.applyColorMap(norm, cv2.COLORMAP_JET)\n",
    "    return colored\n",
    "\n",
    "hello_oakd('disparity', im_proc=disparity_to_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it on the Duckiebot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the code on the robot you need to run:<br>\n",
    "   `dts oakd test -b DB_NAME -L default`<br>\n",
    "or in this case just <br>\n",
    "   `dts oakd test -b DB_NAME`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command converts the code we wrote in this Jupyter notebook into a Python script and will run it into a docker container around a ROS wrapper we created.<br>\n",
    "To visualize the results you need to run:<br>\n",
    "`dts start_gui_tools DB_NAME`<br>\n",
    "From inside this container then you can run `rqt`.<br>\n",
    "When RQT opens navigate to Plugins->Visualization->Image View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Next steps\n",
    "\n",
    "Congratulations, you just created a basic pipeline to read the images from the OAK-D and stream them on a Duckiebot!\n",
    "You can now proceed to the next activity: [Stereo calibration](../02-oakd-calibration/oakd-calibration.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
