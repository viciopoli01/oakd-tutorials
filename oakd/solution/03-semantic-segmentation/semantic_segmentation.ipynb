{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: right\">\n",
    "  <img src=\"../images/dtlogo.png\" alt=\"Logo\" width=\"200\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš™ðŸ’» 03 - OAKD semantic segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you will learn how to create a pipeline to make inference on the images acquired by the **OAK-D**.<br>\n",
    "Plug the **OAK-D** to youlaptop and start running the notebook's cells.<br>\n",
    "This notebook can also be run on a **Duckiebot** (tested with DB21M)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import numpy as np\n",
    "import cv2\n",
    "from typing import List, Dict, Callable, Optional, Any\n",
    "\n",
    "import depthai as dai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a pipeline\n",
    "\n",
    "The \"pipeline\" is an object documented in the [`depthai` API](https://docs.luxonis.com/projects/api/en/latest/) and can be initialized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def create_pipeline() -> dai.Pipeline:\n",
    "    pipeline = dai.Pipeline()\n",
    "    pipeline.setOpenVINOVersion(version=dai.OpenVINO.Version.VERSION_2021_3)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and configuring nodes\n",
    "\n",
    "\"Nodes\" (not ROS nodes) are different types of sensing modalities of the OAK-D. For example: images, stereo, or neural networks. They are configured using a \"pipeline\" object as a reference, which tracks all of the nodes that get created and pass them onto the OAK-D hardware to configure the device internally once the structure is defined.\n",
    "\n",
    "In this example, we will configure a node for the central RGB camera and nodes that are necessary to run a ML model trained for semantic segmentation in the Duckietown world. An image manipulation node is necessary to pre-process RGB images into the correct shape. Pixel intensities are normalized within the NN model to have the expected mean and standard deviation (this is taken care of during model conversion in OpenVINO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def create_nodes(pipeline: dai.Pipeline, model_path: str) -> Dict[str, dai.Node]:\n",
    "    # RGB CAMERA\n",
    "    cam_rgb = pipeline.createColorCamera()\n",
    "    cam_rgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n",
    "    cam_rgb.setResolution(\n",
    "        dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "    cam_rgb.setColorOrder(\n",
    "        dai.ColorCameraProperties.ColorOrder.RGB)\n",
    "    cam_rgb.setInterleaved(False)\n",
    "    cam_rgb.setPreviewSize(640, 400)\n",
    "\n",
    "    # SEMANTIC SEGMENTATION NEURAL NETWORK\n",
    "    blobfile = model_path\n",
    "    if not os.path.exists(blobfile) or not os.path.isfile(blobfile):\n",
    "        print('Model not found! Blob file: %s' % blobfile)\n",
    "        assert False\n",
    "    segmentation_nn = pipeline.createNeuralNetwork()\n",
    "    segmentation_nn.setBlobPath(blobfile)\n",
    "    segmentation_nn.input.setBlocking(False)\n",
    "    segmentation_nn.setNumInferenceThreads(2)  # 3 = max for OAK-D\n",
    "\n",
    "    # IMAGE MANIPULATION\n",
    "    manip_rgb = pipeline.createImageManip()\n",
    "    manip_rgb.initialConfig.setResize(640, 480)\n",
    "    manip_rgb.setWaitForConfigInput(False)\n",
    "    manip_rgb.setKeepAspectRatio(False)\n",
    "\n",
    "    return {\n",
    "        'rgb': cam_rgb,\n",
    "        'manip': manip_rgb,\n",
    "        'seg': segmentation_nn\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "\n",
    "Output links are [a special type of node](https://docs.luxonis.com/projects/api/en/latest/components/nodes/xlink_out/) which exist at the interface of the OAK-D hardware and the interface of your computer or Duckiebot. They provide a way to access the data perceived by the OAK-D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def create_output_links(pipeline: dai.Pipeline) -> Dict[str, dai.XLinkOut]:\n",
    "    xout_links = {\n",
    "        'rgb': pipeline.createXLinkOut(),\n",
    "        'seg': pipeline.createXLinkOut()\n",
    "    }\n",
    "    for name, xout_link in xout_links.items():\n",
    "        xout_link.setStreamName(name)\n",
    "        xout_link.input.setBlocking(False)\n",
    "    return xout_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking nodes to each other\n",
    "\n",
    "The various inputs and outputs of nodes need to be linked together to define the data flow, i.e. _what_ goes _where_? This will be tracked internally by the \"pipeline\" object and later used to configure the OAK-D device. For the output nodes, they need to know which \"upstream\" node in the computational graph they should be receiving data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def link_nodes_and_outputs(nodes: Dict[str, dai.Node],\n",
    "                           outputs: Dict[str, dai.XLinkOut]) -> None:\n",
    "    # Raw RGB image --> Output to host\n",
    "    nodes['rgb'].preview.link(outputs['rgb'].input)\n",
    "    # Raw RGB image --> Image manipulation module\n",
    "    nodes['rgb'].preview.link(nodes['manip'].inputImage)\n",
    "    # Manipulated RGB image --> Neural network\n",
    "    nodes['manip'].out.link(nodes['seg'].input)\n",
    "    # Segmentation image --> Output to host\n",
    "    nodes['seg'].out.link(outputs['seg'].input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a device\n",
    "\n",
    "Once all of the nodes are initialized, configured, and properly linked together, the device can be created. The computer or Duckiebot will try to search for an OAK-D device using the `depthai` library and to configure the hardware using our \"pipeline\" object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def create_device(pipeline: dai.Pipeline) -> dai.Device:\n",
    "    device = dai.Device(pipeline, usb2Mode=False)\n",
    "    device.setLogLevel(dai.LogLevel.DEBUG)\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output queues\n",
    "\n",
    "Remember those special \"output links\"? In order to read them, we need to initialize some \"output queues\" which will link to those outputs on the computer or Duckiebot side of things.\n",
    "\n",
    "If a queue is \"blocking\", when a queue is full, any new incoming data will be dropped from the queue until the first item is read (popped) from the queue and a new space gets freed up. In contrast, a non-blocking queue will always insert new incoming data into the queue, and if the queue is filled up, the oldest data will get dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def create_output_queues(device: dai.Device,\n",
    "                         outputs: Dict[str, dai.XLinkOut]) -> Dict[str, dai.DataOutputQueue]:\n",
    "    queues = dict()\n",
    "    for name, xout_link in outputs.items():\n",
    "        queues[name] = device.getOutputQueue(name=name, maxSize=1, blocking=False)\n",
    "    return queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "With everything set up, let's create a utility function to read some specific requested data from the OAK-D, and return it in a dictionary mapping from the data name to the raw data (e.g. a Numpy array containing image data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def read_data(requested_data: List[str],\n",
    "              output_queues: Dict[str, dai.DataOutputQueue]) -> Dict[str, Any]:\n",
    "    data = {name: None for name in requested_data}\n",
    "    for name in requested_data:\n",
    "        if name not in output_queues.keys():\n",
    "            continue\n",
    "        if name == 'rgb':\n",
    "            data[name] = output_queues[name].get().getCvFrame()\n",
    "        elif name == 'seg':\n",
    "            # Read raw bytes from the final layer (output) of the neural net\n",
    "            segmentation = output_queues[name].get().getLayerFp16('output')\n",
    "            # Convert to numpy array\n",
    "            segmentation = np.asarray(segmentation, dtype=np.float16)\n",
    "            # Reshape to (C, H, W)\n",
    "            segmentation = segmentation.reshape((-1, 480, 640))\n",
    "            # Compress 1-hot encoding of classes to a single dimension\n",
    "            segmentation = np.argmax(segmentation, axis=0).astype(np.uint8)\n",
    "            # Resize to the same image size as the original RGB\n",
    "            segmentation = cv2.resize(segmentation, (640, 400), cv2.INTER_NEAREST)\n",
    "            # Save to dictionary\n",
    "            data[name] = segmentation\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and visualize\n",
    "\n",
    "Here is a simple helper function which uses the functions we've written to set up the OAK-D, continuously read data, and visualize it. This function optionally includes an \"image processing\" function which post-processes the data that we will read. This will come in handy for visualizing segmentation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "ImageProcFunc = Callable[[np.ndarray], np.ndarray]\n",
    "\n",
    "def hello_oakd(output_name: str,\n",
    "               im_proc: Optional[ImageProcFunc]=None) -> None:\n",
    "    display_handle = display(None, display_id=True)\n",
    "    pipeline = create_pipeline()\n",
    "    nodes = create_nodes(pipeline,'../src/oakd_pkg/models/segmentation_model.blob')\n",
    "    outputs = create_output_links(pipeline)\n",
    "    link_nodes_and_outputs(nodes, outputs)\n",
    "    device = create_device(pipeline)\n",
    "    output_queues = create_output_queues(device, outputs)\n",
    "    try:\n",
    "        while True:\n",
    "            data = read_data([output_name], output_queues)\n",
    "            if output_name in data.keys():\n",
    "                frame = data[output_name]\n",
    "                if im_proc is not None:\n",
    "                    frame = im_proc(frame)\n",
    "                _, frame = cv2.imencode('.jpeg', frame)\n",
    "                display_handle.update(Image(data=frame.tobytes()))\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        pass\n",
    "        # display_handle.update(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_oakd('rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize(im: np.ndarray) -> np.ndarray:\n",
    "    colors = [\n",
    "        (0, 0, 0),\n",
    "        (0, 220, 220),\n",
    "        (35, 142, 107),\n",
    "        (70, 70, 70),\n",
    "        (60, 20, 220),\n",
    "        (128, 64, 128),\n",
    "        (142, 0, 0),\n",
    "        (30, 170, 250),\n",
    "        (140, 150, 230)\n",
    "    ]\n",
    "    out = np.take(colors, im, axis=0).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "hello_oakd('seg', im_proc=colorize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it on a Duckiebot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\"><img src=\"../images/duckseg.png\" width=\"500\" alt=\"oakd on db\"></p>\n",
    "\n",
    "\n",
    "To test this tutorial on a Duckiebot you must have a fully configured robot.<br>\n",
    "Plug the OAK-D to the robot and run the command:<br><br>\n",
    "`dts oakd test DB_NAME -L default` <br><br>\n",
    "or in this case you can just run:<br><br>\n",
    "`dts oakd test DB_NAME`<br><br>\n",
    "\n",
    "This command convert the cells of the notebook into a python script and run it in a ROS wrapper we created.<br>\n",
    "It means that you can also visualize and use the stream in ROS.<br>\n",
    "Run:<br><br>\n",
    "`dts start_gui_tools DB_NAME`<br><br>\n",
    "Navigate to Plugins->Visualize->Image View , and select from the dropdown menu the topic you want to visualize.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
